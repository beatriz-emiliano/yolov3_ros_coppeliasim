<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Strict//EN"><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Language" content="en-us">
<title>simVision API</title>
<link rel="stylesheet" type="text/css" href="../../helpFiles/style.css">
<script type="text/javascript">
//
function getParameterByName(name, url = window.location.href)
{
    name = name.replace(/[\[\]]/g, '\\$&');
    var regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)'),
        results = regex.exec(url);
    if(!results) return null;
    if(!results[2]) return '';
    return decodeURIComponent(results[2].replace(/\+/g, ' '));
}
//
                </script><style type="text/css">
td.section { margin: 0; padding: 0; }
                </style></head>
<body>
<div align="center"><table class="allEncompassingTable">

<tr><td id="title" class="section"><h1>Vision plugin API reference</h1></td></tr>
<tr><td id="info" class="section"><p class="warningBox">API functions for performing simple image processing, and handling special types of vision algorithms.</p></td></tr>

<tr><td id="alphabetical" class="section"><pre class="apiList">
<a href="?#simVision.addBuffer1ToWorkImg">simVision.addBuffer1ToWorkImg</a>
<a href="?#simVision.addWorkImgToBuffer1">simVision.addWorkImgToBuffer1</a>
<a href="?#simVision.binaryWorkImg">simVision.binaryWorkImg</a>
<a href="?#simVision.blobDetectionOnWorkImg">simVision.blobDetectionOnWorkImg</a>
<a href="?#simVision.buffer1ToWorkImg">simVision.buffer1ToWorkImg</a>
<a href="?#simVision.buffer2ToWorkImg">simVision.buffer2ToWorkImg</a>
<a href="?#simVision.changedPixelsOnWorkImg">simVision.changedPixelsOnWorkImg</a>
<a href="?#simVision.circularCutWorkImg">simVision.circularCutWorkImg</a>
<a href="?#simVision.colorSegmentationOnWorkImg">simVision.colorSegmentationOnWorkImg</a>
<a href="?#simVision.coordinatesFromWorkImg">simVision.coordinatesFromWorkImg</a>
<a href="?#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>
<a href="?#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>
<a href="?#simVision.destroyVelodyneHDL64E">simVision.destroyVelodyneHDL64E</a>
<a href="?#simVision.destroyVelodyneVPL16">simVision.destroyVelodyneVPL16</a>
<a href="?#simVision.distort">simVision.distort</a>
<a href="?#simVision.edgeDetectionOnWorkImg">simVision.edgeDetectionOnWorkImg</a>
<a href="?#simVision.handleAnaglyphStereo">simVision.handleAnaglyphStereo</a>
<a href="?#simVision.handleSpherical">simVision.handleSpherical</a>
<a href="?#simVision.handleVelodyneHDL64E">simVision.handleVelodyneHDL64E</a>
<a href="?#simVision.handleVelodyneVPL16">simVision.handleVelodyneVPL16</a>
<a href="?#simVision.horizontalFlipWorkImg">simVision.horizontalFlipWorkImg</a>
<a href="?#simVision.intensityScaleOnWorkImg">simVision.intensityScaleOnWorkImg</a>
<a href="?#simVision.matrix3x3OnWorkImg">simVision.matrix3x3OnWorkImg</a>
<a href="?#simVision.matrix5x5OnWorkImg">simVision.matrix5x5OnWorkImg</a>
<a href="?#simVision.multiplyWorkImgWithBuffer1">simVision.multiplyWorkImgWithBuffer1</a>
<a href="?#simVision.normalizeWorkImg">simVision.normalizeWorkImg</a>
<a href="?#simVision.rectangularCutWorkImg">simVision.rectangularCutWorkImg</a>
<a href="?#simVision.resizeWorkImg">simVision.resizeWorkImg</a>
<a href="?#simVision.rotateWorkImg">simVision.rotateWorkImg</a>
<a href="?#simVision.scaleAndOffsetWorkImg">simVision.scaleAndOffsetWorkImg</a>
<a href="?#simVision.selectiveColorOnWorkImg">simVision.selectiveColorOnWorkImg</a>
<a href="?#simVision.sensorDepthMapToWorkImg">simVision.sensorDepthMapToWorkImg</a>
<a href="?#simVision.sensorImgToWorkImg">simVision.sensorImgToWorkImg</a>
<a href="?#simVision.sharpenWorkImg">simVision.sharpenWorkImg</a>
<a href="?#simVision.shiftWorkImg">simVision.shiftWorkImg</a>
<a href="?#simVision.subtractBuffer1FromWorkImg">simVision.subtractBuffer1FromWorkImg</a>
<a href="?#simVision.subtractWorkImgFromBuffer1">simVision.subtractWorkImgFromBuffer1</a>
<a href="?#simVision.swapBuffers">simVision.swapBuffers</a>
<a href="?#simVision.swapWorkImgWithBuffer1">simVision.swapWorkImgWithBuffer1</a>
<a href="?#simVision.uniformImgToWorkImg">simVision.uniformImgToWorkImg</a>
<a href="?#simVision.velodyneDataFromWorkImg">simVision.velodyneDataFromWorkImg</a>
<a href="?#simVision.verticalFlipWorkImg">simVision.verticalFlipWorkImg</a>
<a href="?#simVision.workImgToBuffer1">simVision.workImgToBuffer1</a>
<a href="?#simVision.workImgToBuffer2">simVision.workImgToBuffer2</a>
<a href="?#simVision.workImgToSensorDepthMap">simVision.workImgToSensorDepthMap</a>
<a href="?#simVision.workImgToSensorImg">simVision.workImgToSensorImg</a></pre>
<br>
</td></tr>

<tr><td id="category" class="section">

<h2><a name="environment"></a>Handling special types of sensors</h2>
<pre class=apiList>
<a href="?#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>
<a href="?#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>
<a href="?#simVision.destroyVelodyneHDL64E">simVision.destroyVelodyneHDL64E</a>
<a href="?#simVision.destroyVelodyneVPL16">simVision.destroyVelodyneVPL16</a>
<a href="?#simVision.distort">simVision.distort</a>
<a href="?#simVision.handleAnaglyphStereo">simVision.handleAnaglyphStereo</a>
<a href="?#simVision.handleSpherical">simVision.handleSpherical</a>
<a href="?#simVision.handleVelodyneHDL64E">simVision.handleVelodyneHDL64E</a>
<a href="?#simVision.handleVelodyneVPL16">simVision.handleVelodyneVPL16</a>
</pre>


<h2><a name="simpleProcessing"></a>Simple image handling and processing</h2>
<pre class=apiList>
<a href="?#simVision.addBuffer1ToWorkImg">simVision.addBuffer1ToWorkImg</a>
<a href="?#simVision.addWorkImgToBuffer1">simVision.addWorkImgToBuffer1</a>
<a href="?#simVision.binaryWorkImg">simVision.binaryWorkImg</a>
<a href="?#simVision.blobDetectionOnWorkImg">simVision.blobDetectionOnWorkImg</a>
<a href="?#simVision.buffer1ToWorkImg">simVision.buffer1ToWorkImg</a>
<a href="?#simVision.buffer2ToWorkImg">simVision.buffer2ToWorkImg</a>
<a href="?#simVision.changedPixelsOnWorkImg">simVision.changedPixelsOnWorkImg</a>
<a href="?#simVision.circularCutWorkImg">simVision.circularCutWorkImg</a>
<a href="?#simVision.colorSegmentationOnWorkImg">simVision.colorSegmentationOnWorkImg</a>
<a href="?#simVision.coordinatesFromWorkImg">simVision.coordinatesFromWorkImg</a>
<a href="?#simVision.edgeDetectionOnWorkImg">simVision.edgeDetectionOnWorkImg</a>
<a href="?#simVision.horizontalFlipWorkImg">simVision.horizontalFlipWorkImg</a>
<a href="?#simVision.intensityScaleOnWorkImg">simVision.intensityScaleOnWorkImg</a>
<a href="?#simVision.matrix3x3OnWorkImg">simVision.matrix3x3OnWorkImg</a>
<a href="?#simVision.matrix5x5OnWorkImg">simVision.matrix5x5OnWorkImg</a>
<a href="?#simVision.multiplyWorkImgWithBuffer1">simVision.multiplyWorkImgWithBuffer1</a>
<a href="?#simVision.normalizeWorkImg">simVision.normalizeWorkImg</a>
<a href="?#simVision.rectangularCutWorkImg">simVision.rectangularCutWorkImg</a>
<a href="?#simVision.resizeWorkImg">simVision.resizeWorkImg</a>
<a href="?#simVision.rotateWorkImg">simVision.rotateWorkImg</a>
<a href="?#simVision.scaleAndOffsetWorkImg">simVision.scaleAndOffsetWorkImg</a>
<a href="?#simVision.selectiveColorOnWorkImg">simVision.selectiveColorOnWorkImg</a>
<a href="?#simVision.sensorDepthMapToWorkImg">simVision.sensorDepthMapToWorkImg</a>
<a href="?#simVision.sensorImgToWorkImg">simVision.sensorImgToWorkImg</a>
<a href="?#simVision.sharpenWorkImg">simVision.sharpenWorkImg</a>
<a href="?#simVision.shiftWorkImg">simVision.shiftWorkImg</a>
<a href="?#simVision.subtractBuffer1FromWorkImg">simVision.subtractBuffer1FromWorkImg</a>
<a href="?#simVision.subtractWorkImgFromBuffer1">simVision.subtractWorkImgFromBuffer1</a>
<a href="?#simVision.swapBuffers">simVision.swapBuffers</a>
<a href="?#simVision.swapWorkImgWithBuffer1">simVision.swapWorkImgWithBuffer1</a>
<a href="?#simVision.uniformImgToWorkImg">simVision.uniformImgToWorkImg</a>
<a href="?#simVision.velodyneDataFromWorkImg">simVision.velodyneDataFromWorkImg</a>
<a href="?#simVision.verticalFlipWorkImg">simVision.verticalFlipWorkImg</a>
<a href="?#simVision.workImgToBuffer1">simVision.workImgToBuffer1</a>
<a href="?#simVision.workImgToBuffer2">simVision.workImgToBuffer2</a>
<a href="?#simVision.workImgToSensorDepthMap">simVision.workImgToSensorDepthMap</a>
<a href="?#simVision.workImgToSensorImg">simVision.workImgToSensorImg</a>
</pre>
</td></tr>

<tr><td id="commands" class="section">
<p class=subsectionBar><a name="simVision.createVelodyneHDL64E" id="simVision.createVelodyneHDL64E"></a>simVision.createVelodyneHDL64E</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Creates a handle for generating data similar to a Velodyne HDL64E. See also <a href="#simVision.destroyVelodyneHDL64E">simVision.destroyVelodyneHDL64E</a> and <a href="#simVision.handleVelodyneHDL64E">simVision.handleVelodyneHDL64E</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int handle=simVision.createVelodyneHDL64E(int[4] visionSensorHandles,float frequency,int options=0,int pointSize=2,float[2] coloring_closeFarDist={1,5},float displayScalingFactor=1,int pointCloudHandle=-1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>rgbVisionSensorHandle</strong>: handle of a passive vision sensor, receiving the computed RGB image.</div>
<div><strong>visionSensorHandles</strong>: the handles of 4 active vision sensors, looking to the front, left, rear and right.</div>
<div><strong>frequency</strong>: the rotation frequency.</div>
<div><strong>options</strong>: bit-coded options:</div>
<div class=tab>bit0 set (i.e. 1): do not display points</div>
<div class=tab>bit1 set( i.e. 2): display only current points.</div>
<div class=tab>bit2 set( i.e. 4): returned data is polar (otherwise cartesian).</div>
<div class=tab>bit3 set( i.e. 8): displayed points are emissive.</div>
<div><strong>pointSize</strong>: the size of the displayed points, in pixels.</div>
<div><strong>coloring_closeFarDist</strong>: the close and far distances, used to adjust intensity coloring.</div>
<div><strong>displayScalingFactor</strong>: a scaling factor applied radially to each point. Can be used to bring points slightly closer to the sensor, to avoid points being hidden behind surfaces due to depth map resolution.</div>
<div><strong>pointCloudHandle</strong>: the optional handle of a point cloud object (that will be in charge of displaying the detected points.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>handle</strong>: the created Velodyne HDL64E handle.</div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int handle=simVision.createVelodyneHDL64E(list visionSensorHandles,float frequency,int options=0,int pointSize=2,list coloring_closeFarDist=[1,5],float displayScalingFactor=1,int pointCloudHandle=-1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.createVelodyneVPL16" id="simVision.createVelodyneVPL16"></a>simVision.createVelodyneVPL16</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Creates a handle for generating data similar to a Velodyne VPL16. See also <a href="#simVision.destroyVelodyneVPL16">simVision.destroyVelodyneVPL16</a> and <a href="#simVision.handleVelodyneVPL16">simVision.handleVelodyneVPL16</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int handle=simVision.createVelodyneVPL16(int[4] visionSensorHandles,float frequency,int options=0,int pointSize=2,float[2] coloring_closeFarDist={1,5},float displayScalingFactor=1,int pointCloudHandle=-1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>rgbVisionSensorHandle</strong>: handle of a passive vision sensor, receiving the computed RGB image.</div>
<div><strong>visionSensorHandles</strong>: the handles of 4 active vision sensors, looking to the front, left, rear and right.</div>
<div><strong>frequency</strong>: the rotation frequency.</div>
<div><strong>options</strong>: bit-coded options:</div>
<div class=tab>bit0 set (i.e. 1): do not display points</div>
<div class=tab>bit1 set( i.e. 2): display only current points.</div>
<div class=tab>bit2 set( i.e. 4): returned data is polar (otherwise cartesian).</div>
<div class=tab>bit3 set( i.e. 8): displayed points are emissive.</div>
<div><strong>pointSize</strong>: the size of the displayed points, in pixels.</div>
<div><strong>coloring_closeFarDist</strong>: the close and far distances, used to adjust intensity coloring.</div>
<div><strong>displayScalingFactor</strong>: a scaling factor applied radially to each point. Can be used to bring points slightly closer to the sensor, to avoid points being hidden behind surfaces due to depth map resolution.</div>
<div><strong>pointCloudHandle</strong>: the optional handle of a point cloud object (that will be in charge of displaying the detected points.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>handle</strong>: the created Velodyne VPL16 handle.</div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int handle=simVision.createVelodyneVPL16(list visionSensorHandles,float frequency,int options=0,int pointSize=2,list coloring_closeFarDist=[1,5],float displayScalingFactor=1,int pointCloudHandle=-1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.destroyVelodyneHDL64E" id="simVision.destroyVelodyneHDL64E"></a>simVision.destroyVelodyneHDL64E</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Deletes a Velodyne HDL64E handle previously created with <a href="#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.destroyVelodyneHDL64E(int velodyneHandle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>velodyneHandle</strong>: a handle previously returned by <a href="#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.destroyVelodyneHDL64E(int velodyneHandle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.destroyVelodyneVPL16" id="simVision.destroyVelodyneVPL16"></a>simVision.destroyVelodyneVPL16</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Deletes a Velodyne VPL16 handle previously created with <a href="#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.destroyVelodyneVPL16(int velodyneHandle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>velodyneHandle</strong>: a handle previously returned by <a href="#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.destroyVelodyneVPL16(int velodyneHandle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.distort" id="simVision.distort"></a>simVision.distort</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Transforms (distorts) a vision sensor image via pixel remapping.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.distort(int visionSensorHandle,int[] pixelMap=nil,float[] depthScalings=nil)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>visionSensorHandle</strong>: the handle of the vision sensor.</div>
<div><strong>pixelMap</strong>: a table containing indices to new pixel positions. Should be of size resX*resY. Consecutive, incremental indices (starting at 0) represents the identity transformation. Can be omitted if a map was previously provided and doesn't need change.</div>
<div><strong>depthScaling</strong>: an optional table containing scaling factors for each depth value.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.distort(int visionSensorHandle,list pixelMap=None,list depthScalings=None)</td> 
</tr>

</table> 
<br>






<p class=subsectionBar><a name="simVision.handleAnaglyphStereo" id="simVision.handleAnaglyphStereo"></a>simVision.handleAnaglyphStereo</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Allows to generate an anaglyph stereo image from two individual vision sensors (for the left and right eye).</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.handleAnaglyphStereo(int rgbVisionSensorHandle,int[2] handlesOfTwoVisionSensors,float[6] leftAndRightColors=nil)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>rgbVisionSensorHandle</strong>: handle of a passive vision sensor, receiving the computed RGB image.</div>
<div><strong>handlesOfTwoVisionSensors</strong>: the handles of two active vision sensors (for the left and right eye).</div>
<div><strong>leftAndRightColors</strong>: the colors for the left and right eye rendering.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.handleAnaglyphStereo(int rgbVisionSensorHandle,list handlesOfTwoVisionSensors,list leftAndRightColors=None)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.handleSpherical" id="simVision.handleSpherical"></a>simVision.handleSpherical</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Allows to generate an RGB and/or depth image that covers all directions, i.e. spherical vision, based on the input of 6 individual vision sensors, each looking into a different and perpendicular direction.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.handleSpherical(int rgbVisionSensorHandle,int[6] handlesOfSixVisionSensors,float horizontalAngle,float verticalAngle,int depthVisionSensorHandle=-1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>rgbVisionSensorHandle</strong>: handle of a passive vision sensor, receiving the computed RGB spherical image.</div>
<div><strong>handlesOfSixVisionSensors</strong>: the handles of 6 mutually perpendicular, looking into a different direction active vision sensors.</div>
<div><strong>horizontalAngle</strong>: the desired horizontal view angle, in radians (e.g. 2*math.pi).</div>
<div><strong>horizontalAngle</strong>: the desired vertical view angle, in radians (e.g. math.pi).</div>
<div><strong>depthVisionSensorHandle</strong>: handle of a passive vision sensor, receiving the computed depth image representation of the spherical depth map.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.handleSpherical(int rgbVisionSensorHandle,list handlesOfSixVisionSensors,float horizontalAngle,float verticalAngle,int depthVisionSensorHandle=-1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.handleVelodyneHDL64E" id="simVision.handleVelodyneHDL64E"></a>simVision.handleVelodyneHDL64E</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Handles a velodyne HDL64E sensor (i.e. generates and displays detection points. See also <a href="#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>float[]/buffer points,buffer colors=simVision.handleVelodyneHDL64E(int velodyneHandle,float dt)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>velodyneHandle</strong>: a handle previously returned by <a href="#simVision.createVelodyneHDL64E">simVision.createVelodyneHDL64E</a>. Can be combined with sim.handleflag_abscoords to retrieve points relative to the absolute reference frame, instead of the reference frame of the sensor. Can also be combined with sim.handleflag_codedstring, in order to retrieve packed data (faster).</div>
<div><strong>dt</strong>: the time duration since last call to this function. Typically the simulation time step.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>points</strong>: a table containing the detected points, or a coded string.</div>
<div><strong>colors</strong>: a coded string containing the colors of each point (3 byte values for each point (RGB)). The colors are only returned if the Velodyne model is appropriately configured.</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>list/bytes points,bytes colors=simVision.handleVelodyneHDL64E(int velodyneHandle,float dt)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.handleVelodyneVPL16" id="simVision.handleVelodyneVPL16"></a>simVision.handleVelodyneVPL16</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Handles a velodyne VPL16 sensor (i.e. generates and displays detection points. See also <a href="#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>float[]/buffer points,buffer colors=simVision.handleVelodyneVPL16(int velodyneHandle,float dt)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>velodyneHandle</strong>: a handle previously returned by <a href="#simVision.createVelodyneVPL16">simVision.createVelodyneVPL16</a>. Can be combined with sim.handleflag_abscoords to retrieve points relative to the absolute reference frame, instead of the reference frame of the sensor. Can also be combined with sim.handleflag_codedstring, in order to retrieve packed data (faster).</div>
<div><strong>dt</strong>: the time duration since last call to this function. Typically the simulation time step.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>points</strong>: a table containing the detected points, or a coded string.</div>
<div><strong>colors</strong>: a coded string containing the colors of each point (3 byte values for each point (RGB)). The colors are only returned if the Velodyne model is appropriately configured.</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>list/bytes points,bytes colors=simVision.handleVelodyneVPL16(int velodyneHandle,float dt)</td> 
</tr>

</table> 
<br>


<p class=subsectionBar><a name="simVision.addBuffer1ToWorkImg" id="simVision.addBuffer1ToWorkImg"></a>simVision.addBuffer1ToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a pixel wise addition between the <em>work image</em> and buffer <em>buffer1</em>, and stores the result in the <em>work image</em>. See also <a href="#simVision.addWorkImgToBuffer1">simVision.addWorkImgToBuffer1</a> and <a href="#simVision.subtractBuffer1FromWorkImg">simVision.subtractBuffer1FromWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.addBuffer1ToWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.addBuffer1ToWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.addWorkImgToBuffer1" id="simVision.addWorkImgToBuffer1"></a>simVision.addWorkImgToBuffer1</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a pixel wise addition between the <em>work image</em> and buffer <em>buffer1</em>, and stores the result in buffer <em>buffer1</em>. See also <a href="#simVision.addBuffer1ToWorkImg">simVision.addBuffer1ToWorkImg</a> and <a href="#simVision.subtractWorkImgFromBuffer1">simVision.subtractWorkImgFromBuffer1</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.addWorkImgToBuffer1(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.addWorkImgToBuffer1(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.binaryWorkImg" id="simVision.binaryWorkImg"></a>simVision.binaryWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Transforms the <em>work image</em> into a binary image, with optional triggering.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int trigger,buffer packedPacket=simVision.binaryWorkImg(int handle,float threshold,float oneProportion,float oneTol,float xCenter,float xCenterTol,float yCenter,float yCenterTol,float orient,float orientTol,float roundness,bool enableTrigger,float[3] overlayColor={1.0,0.0,1.0}))</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>threshold</strong>: the threshold for binary 0 or binary 1.</div>
<div><strong>oneProportion</strong>: the nominal binary 1 pixels relative amount (0-1), for triggering.</div>
<div><strong>oneTol</strong>: the allowed tolerance for <em>oneProportion</em>.</div>
<div><strong>xCenter</strong>: the nominal x center of binary 1 pixels (0-1), for triggering.</div>
<div><strong>xCenterTol</strong>: the allowed tolerance for <em>xCenter</em>.</div>
<div><strong>yCenter</strong>: the nominal y center of binary 1 pixels (0-1), for triggering.</div>
<div><strong>yCenterTol</strong>: the allowed tolerance for <em>yCenter</em>.</div>
<div><strong>orient</strong>: the nominal orientation, in radians, of the bounding box around binary 1 pixels (0-1), for triggering.</div>
<div><strong>orientTol</strong>: the allowed tolerance for <em>orient</em>.</div>
<div><strong>roundness</strong>: the nominal roundness value of the bounding box around binary 1 pixels (0-1), for triggering.</div>
<div><strong>enableTrigger</strong>: if true and the triggering conditions are met, then return value <em>trigger</em> will be true.</div>
<div><strong>overlayColor</strong>: an overlay color used to visualize triggering conditions. Set to nil for no overlay.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>trigger</strong>: true if the filter has triggered.</div>
<div><strong>packedPacket</strong>: a packed packet (use <a href="regularApi/simUnpackFloatTable.htm">sim.unpackFloatTable</a> to unpack) containing:</div>
<div>a) the binary image <em>proportion</em> value</div>
<div>b) the binary image <em>posX</em> value</div>
<div>c) the binary image <em>posY</em> value</div>
<div>d) the binary image <em>angle</em> value</div>
<div>e) the binary image <em>roundness</em> value</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int trigger,bytes packedPacket=simVision.binaryWorkImg(int handle,float threshold,float oneProportion,float oneTol,float xCenter,float xCenterTol,float yCenter,float yCenterTol,float orient,float orientTol,float roundness,bool enableTrigger,list overlayColor=[1.0,0.0,1.0]))</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.blobDetectionOnWorkImg" id="simVision.blobDetectionOnWorkImg"></a>simVision.blobDetectionOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs blob detection on the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int trigger,buffer packedPacket=simVision.blobDetectionOnWorkImg(int handle,float threshold,float minBlobSize,bool diffColor,float[3] overlayColor={1.0,0.0,1.0}))</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>threshold</strong>: the intensity threshold for a pixel to be considered <em>on</em>. </div>
<div><strong>minBlobSize</strong>: the minimum size of a blob (in relation to the total image surface).</div>
<div><strong>diffColor</strong>: if true then each blob will be represented in a different color.</div>
<div><strong>overlayColor</strong>: an overlay color used to visualize the blobs. Set to nil for no overlay.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>trigger</strong>: always false. Not used.</div>
<div><strong>packedPacket</strong>: a packed packet (use <a href="regularApi/simUnpackFloatTable.htm">sim.unpackFloatTable</a> to unpack) containing:</div>
<div>a) the number of detected blobs</div>
<div>b) the number of values returned for each blob</div>
<div>then for each blob:</div>
<div>c.1) the blob relative size</div>
<div>c.2) the blob orientation</div>
<div>c.3) the blob relative position X</div>
<div>c.4) the blob relative position Y</div>
<div>c.5) the blob bounding box relative width</div>
<div>c.6) the blob bounding box relative height</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int trigger,bytes packedPacket=simVision.blobDetectionOnWorkImg(int handle,float threshold,float minBlobSize,bool diffColor,list overlayColor=[1.0,0.0,1.0]))</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.buffer1ToWorkImg" id="simVision.buffer1ToWorkImg"></a>simVision.buffer1ToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies buffer <em>buffer1</em> to the <em>work image</em>. See also <a href="#simVision.buffer2ToWorkImg">simVision.buffer2ToWorkImg</a>, <a href="#simVision.workImgToBuffer1">simVision.workImgToBuffer1</a>, <a href="#simVision.swapBuffers">simVision.swapBuffers</a> and <a href="#simVision.swapWorkImgWithBuffer1">simVision.swapWorkImgWithBuffer1</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.buffer1ToWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.buffer1ToWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.buffer2ToWorkImg" id="simVision.buffer2ToWorkImg"></a>simVision.buffer2ToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies buffer <em>buffer2</em> to the <em>work image</em>. See also <a href="#simVision.buffer1ToWorkImg">simVision.buffer1ToWorkImg</a>, <a href="#simVision.workImgToBuffer2">simVision.workImgToBuffer2</a> and <a href="#simVision.swapBuffers">simVision.swapBuffers</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.buffer2ToWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.buffer2ToWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.changedPixelsOnWorkImg" id="simVision.changedPixelsOnWorkImg"></a>simVision.changedPixelsOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Returns the pixels that changed the <em>work image</em>, from one frame to the next.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int trigger,buffer packedPacket=simVision.changedPixelsOnWorkImg(int handle,float threshold)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>threshold</strong>: the minimum intensity variation for a pixel to have changed.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>trigger</strong>: always false. Not used.</div>
<div><strong>packedPacket</strong>: a packed packet (use <a href="regularApi/simUnpackFloatTable.htm">sim.unpackFloatTable</a> to unpack) containing for each changed pixel:</div>
<div>a.1) 1 if the pixel became brighter, -1 otherwise</div>
<div>a.2) the x coordinate of the pixel</div>
<div>a.3) the y coordinate of the pixel</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int trigger,bytes packedPacket=simVision.changedPixelsOnWorkImg(int handle,float threshold)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.circularCutWorkImg" id="simVision.circularCutWorkImg"></a>simVision.circularCutWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a circular cut on the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.circularCutWorkImg(int handle,float radius,bool toBuffer1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>radius</strong>: the radius of the disc, expressed proportionally to the image resolution. Pixels outside of the disc's bounds are removed.</div>
<div><strong>toBuffer1</strong>: if true, then the removed pixels are copied to buffer <em>buffer1</em>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.circularCutWorkImg(int handle,float radius,bool toBuffer1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.colorSegmentationOnWorkImg" id="simVision.colorSegmentationOnWorkImg"></a>simVision.colorSegmentationOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a color segmentation on the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.colorSegmentationOnWorkImg(int handle,float colorDistance)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>colorDistance</strong>: the color distance to be used as threshold.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.colorSegmentationOnWorkImg(int handle,float colorDistance)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.coordinatesFromWorkImg" id="simVision.coordinatesFromWorkImg"></a>simVision.coordinatesFromWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Extracts coordinates from the <em>work image</em> (based on the view field of a vision sensor).</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int trigger,buffer packedPacket,buffer colorData=simVision.coordinatesFromWorkImg(int handle,int[2] pointCount,bool angularSpace,bool returnColorData)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor. Can be combined with sim.handleflag_abscoords in order to retrieve points relative to the absolute reference frame, instead of the vision sensor reference frame.</div>
<div><strong>pointCount</strong>: the desired point count along X and Y.</div>
<div><strong>angularSpace</strong>: whether the point sampling happens in the cartesian or angular space (within a given direction).</div>
<div><strong>returnColorData</strong>: whether to also return color data for each point. If true, then the vision sensor's image data should be located in buffer <em>buffer1</em>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>trigger</strong>: always false. Not used.</div>
<div><strong>packedPacket</strong>: a packed packet (use <a href="regularApi/simUnpackFloatTable.htm">sim.unpackFloatTable</a> to unpack) containing:</div>
<div>a) the number of points along X</div>
<div>b) the number of points along Y</div>
<div>then for each points:</div>
<div>c.1) the x coordinate of the point</div>
<div>c.2) the y coordinate of the point</div>
<div>c.3) the z coordinate of the point</div>
<div>c.4) the distance to the point</div>
<div><strong>colorData</strong>: optional color data (use <a href="regularApi/simUnpackUInt8Table.htm">sim.unpackUInt8Table</a> to unpack) containing RGB triplets for each point.</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int trigger,bytes packedPacket,bytes colorData=simVision.coordinatesFromWorkImg(int handle,list pointCount,bool angularSpace,bool returnColorData)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.edgeDetectionOnWorkImg" id="simVision.edgeDetectionOnWorkImg"></a>simVision.edgeDetectionOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Applies an edge detection filter to the <em>work image</em>. See also <a href="#simVision.matrix3x3OnWorkImg">simVision.matrix3x3OnWorkImg</a> and <a href="#simVision.matrix5x5OnWorkImg">simVision.matrix5x5OnWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.edgeDetectionOnWorkImg(int handle,float threshold)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>threshold</strong>: the threshold value.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.edgeDetectionOnWorkImg(int handle,float threshold)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.horizontalFlipWorkImg" id="simVision.horizontalFlipWorkImg"></a>simVision.horizontalFlipWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Horizontally flips the <em>work image</em>. See also <a href="#simVision.verticalFlipWorkImg">simVision.verticalFlipWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.horizontalFlipWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.horizontalFlipWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.intensityScaleOnWorkImg" id="simVision.intensityScaleOnWorkImg"></a>simVision.intensityScaleOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Transforms the <em>work image</em> into an intensity representation.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.intensityScaleOnWorkImg(int handle,float start,float end,bool greyscale)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>start</strong>: the value representing the minimum intensity.</div>
<div><strong>end</strong>: the value representing the maximum intensity.</div>
<div><strong>greyscale</strong>: if true, the output is a grey scale image, otherwise it is a color coded intensity image.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.intensityScaleOnWorkImg(int handle,float start,float end,bool greyscale)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.matrix3x3OnWorkImg" id="simVision.matrix3x3OnWorkImg"></a>simVision.matrix3x3OnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Applies a 3X3 matrix filter to the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.matrix3x3OnWorkImg(int handle,int passes,float multiplier,float[9] matrix)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>passes</strong>: the number of desired filter passes.</div>
<div><strong>multiplier</strong>: a matrix multiplier.</div>
<div><strong>matrix</strong>: the 3X3 matrix.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.matrix3x3OnWorkImg(int handle,int passes,float multiplier,list matrix)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.matrix5x5OnWorkImg" id="simVision.matrix5x5OnWorkImg"></a>simVision.matrix5x5OnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Applies a 5X5 matrix filter to the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.matrix5x5OnWorkImg(int handle,int passes,float multiplier,float[25] matrix)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>passes</strong>: the int of desired filter passes.</div>
<div><strong>multiplier</strong>: a matrix multiplier.</div>
<div><strong>matrix</strong>: the 5X5 matrix.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.matrix5x5OnWorkImg(int handle,int passes,float multiplier,list matrix)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.multiplyWorkImgWithBuffer1" id="simVision.multiplyWorkImgWithBuffer1"></a>simVision.multiplyWorkImgWithBuffer1</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Multiplies (pixel wise) the <em>work image</em> with buffer <em>buffer1</em>, and stores the result in the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.multiplyWorkImgWithBuffer1(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.multiplyWorkImgWithBuffer1(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.normalizeWorkImg" id="simVision.normalizeWorkImg"></a>simVision.normalizeWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Normalizes the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.normalizeWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.normalizeWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.rectangularCutWorkImg" id="simVision.rectangularCutWorkImg"></a>simVision.rectangularCutWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a rectangular cut on the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.rectangularCutWorkImg(int handle,float[2] rectangle,bool toBuffer1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>rectangle</strong>: the x/y size of the rectangle, expressed proportionally to the image resolution. Pixels outside of the rectangle's bounds are removed.</div>
<div><strong>toBuffer1</strong>: if true, then the removed pixels are copied to buffer <em>buffer1</em>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.rectangularCutWorkImg(int handle,list rectangle,bool toBuffer1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.resizeWorkImg" id="simVision.resizeWorkImg"></a>simVision.resizeWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Scales the <em>work image</em>. The resolution remains same.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.resizeWorkImg(int handle,float[2] scaling)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>scaling</strong>: the x/y scaling.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.resizeWorkImg(int handle,list scaling)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.rotateWorkImg" id="simVision.rotateWorkImg"></a>simVision.rotateWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Performs a rotation of the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.rotateWorkImg(int handle,float angle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>angle</strong>: the rotation angle in radians.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.rotateWorkImg(int handle,float angle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.scaleAndOffsetWorkImg" id="simVision.scaleAndOffsetWorkImg"></a>simVision.scaleAndOffsetWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Shifts and scales colors of the <em>work image</em>, in the RGB or HSL space: colorOut=postOffset+(colorIn+preOffset)*scaling</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.scaleAndOffsetWorkImg(int handle,float[3] colorPreOffset,float[3] colorScaling,float[3] colorPostOffset,bool rgbSpace)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>colorPreOffset</strong>: the pre-offset, in RGB or HSL space.</div>
<div><strong>colorScaling</strong>: the scaling, in RGB or HSL space.</div>
<div><strong>colorPostOffset</strong>: the post-offset, in RGB or HSL space.</div>
<div><strong>rgbSpace</strong>: if true, values are in the RGB space, otherwise they are in the HSL space.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.scaleAndOffsetWorkImg(int handle,list colorPreOffset,list colorScaling,list colorPostOffset,bool rgbSpace)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.selectiveColorOnWorkImg" id="simVision.selectiveColorOnWorkImg"></a>simVision.selectiveColorOnWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Selects a specific color in the RGB or HSL space of the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.selectiveColorOnWorkImg(int handle,float[3] nominalColor,float[3] colorTolerance,bool rgbSpace,bool keepColor,bool toBuffer1)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>nominalColor</strong>: the nominal color to select, in RGB or HSL space.</div>
<div><strong>colorTolerance</strong>: the tolerance around the nominal color, in RGB or HSL space.</div>
<div><strong>rgbSpace</strong>: if true, values are in the RGB space, otherwise they are in the HSL space.</div>
<div><strong>keepColor</strong>: if true, the specified color is kept, otherwise it is removed.</div>
<div><strong>toBuffer1</strong>: if true, the removed color is copied to buffer <em>buffer1</em>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.selectiveColorOnWorkImg(int handle,list nominalColor,list colorTolerance,bool rgbSpace,bool keepColor,bool toBuffer1)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.sensorDepthMapToWorkImg" id="simVision.sensorDepthMapToWorkImg"></a>simVision.sensorDepthMapToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the depth buffer acquired by a vision sensor to the <em>work image</em> (buffer used for image processing). see also <a href="#simVision.sensorImgToWorkImg">simVision.sensorImgToWorkImg</a> and <a href="#simVision.workImgToSensorImg">simVision.workImgToSensorImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.sensorDepthMapToWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.sensorDepthMapToWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.sensorImgToWorkImg" id="simVision.sensorImgToWorkImg"></a>simVision.sensorImgToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the RGB image acquired by a vision sensor to the <em>work image</em> (buffer used for image processing). See also <a href="#simVision.sensorDepthMapToWorkImg">simVision.sensorDepthMapToWorkImg</a> and <a href="#simVision.workImgToSensorImg">simVision.workImgToSensorImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.sensorImgToWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.sensorImgToWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.sharpenWorkImg" id="simVision.sharpenWorkImg"></a>simVision.sharpenWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Sharpens the <em>work image</em>. See also <a href="#simVision.matrix3x3OnWorkImg">simVision.matrix3x3OnWorkImg</a> and <a href="#simVision.matrix5x5OnWorkImg">simVision.matrix5x5OnWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.sharpenWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.sharpenWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.shiftWorkImg" id="simVision.shiftWorkImg"></a>simVision.shiftWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Shifts the <em>work image</em>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.shiftWorkImg(int handle,float[2] shift,bool wrap)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>shift</strong>: the x/y shift amount, proportional to the image resolution (0=no shift, 1=shift by x/y resolution pixels).</div>
<div><strong>wrap</strong>: whether parts shifted outside the image frame wrap around.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.shiftWorkImg(int handle,list shift,bool wrap)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.subtractBuffer1FromWorkImg" id="simVision.subtractBuffer1FromWorkImg"></a>simVision.subtractBuffer1FromWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Subtracts (pixel wise subtraction) buffer <em>buffer1</em> from the <em>work image</em>. See also <a href="#simVision.subtractWorkImgFromBuffer1">simVision.subtractWorkImgFromBuffer1</a> and <a href="#simVision.addBuffer1ToWorkImg">simVision.addBuffer1ToWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.subtractBuffer1FromWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.subtractBuffer1FromWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.subtractWorkImgFromBuffer1" id="simVision.subtractWorkImgFromBuffer1"></a>simVision.subtractWorkImgFromBuffer1</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Subtracts (pixel wise subtraction) the <em>work image</em> from buffer <em>buffer1</em>. See also <a href="#simVision.subtractBuffer1FromWorkImg">simVision.subtractBuffer1FromWorkImg</a> and <a href="#simVision.addWorkImgToBuffer1">simVision.addWorkImgToBuffer1</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.subtractWorkImgFromBuffer1(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.subtractWorkImgFromBuffer1(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.swapBuffers" id="simVision.swapBuffers"></a>simVision.swapBuffers</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Swaps buffer <em>buffer1</em> with buffer <em>buffer2</em>. See also <a href="#simVision.swapWorkImgWithBuffer1">simVision.swapWorkImgWithBuffer1</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.swapBuffers(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.swapBuffers(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.swapWorkImgWithBuffer1" id="simVision.swapWorkImgWithBuffer1"></a>simVision.swapWorkImgWithBuffer1</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Swaps the <em>work image</em> with buffer <em>buffer1</em>. See also <a href="#simVision.swapBuffers">simVision.swapBuffers</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.swapWorkImgWithBuffer1(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.swapWorkImgWithBuffer1(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.uniformImgToWorkImg" id="simVision.uniformImgToWorkImg"></a>simVision.uniformImgToWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Applies a uniform color to the <em>work image</em> (buffer used for image processing)</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.uniformImgToWorkImg(int handle,float[3] color)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
<div><strong>color</strong>: a table containing the RGB-triplet for the color (in the range of 0-1).</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.uniformImgToWorkImg(int handle,list color)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.velodyneDataFromWorkImg" id="simVision.velodyneDataFromWorkImg"></a>simVision.velodyneDataFromWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Extracts Velodyne coordinates from the <em>work image</em> (based on the view field of a vision sensor).</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>int trigger,buffer packedPacket,buffer colorData=simVision.velodyneDataFromWorkImg(int handle,int[2] pointCount,float verticalScanAngle,bool returnColorData=false)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor. Can be combined with sim.handleflag_abscoords in order to retrieve points relative to the absolute reference frame, instead of the vision sensor reference frame.</div>
<div><strong>pointCount</strong>: the desired point count along X and Y.</div>
<div><strong>verticalScanAngle</strong>: the vertical scan angle.</div>
<div><strong>returnColorData</strong>: whether to also return color data for each point. If true, then the vision sensor's image data should be located in buffer <em>buffer1</em>.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div><strong>trigger</strong>: always false. Not used.</div>
<div><strong>packedPacket</strong>: a packed packet (use <a href="regularApi/simUnpackFloatTable.htm">sim.unpackFloatTable</a> to unpack) containing:</div>
<div>a) the number of points along X</div>
<div>b) the number of points along Y</div>
<div>then for each points:</div>
<div>c.1) the x coordinate of the point</div>
<div>c.2) the y coordinate of the point</div>
<div>c.3) the z coordinate of the point</div>
<div>c.4) the distance from the sensor to the point</div>
<div><strong>colorData</strong>: optional color data (use <a href="regularApi/simUnpackUInt8Table.htm">sim.unpackUInt8Table</a> to unpack) containing RGB triplets for each point.</div>
</td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>int trigger,bytes packedPacket,bytes colorData=simVision.velodyneDataFromWorkImg(int handle,list pointCount,float verticalScanAngle,bool returnColorData=False)</td> 
</tr>

</table> 
<br>




<p class=subsectionBar><a name="simVision.verticalFlipWorkImg" id="simVision.verticalFlipWorkImg"></a>simVision.verticalFlipWorkImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Vertically flips the <em>work image</em>. See also <a href="#simVision.horizontalFlipWorkImg">simVision.horizontalFlipWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.verticalFlipWorkImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.verticalFlipWorkImg(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.workImgToBuffer1" id="simVision.workImgToBuffer1"></a>simVision.workImgToBuffer1</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the <em>work image</em> to buffer <em>buffer1</em>. See also <a href="#simVision.workImgToBuffer2">simVision.workImgToBuffer2</a>, <a href="#simVision.buffer1ToWorkImg">simVision.buffer1ToWorkImg</a>, <a href="#simVision.swapBuffers">simVision.swapBuffers</a> and <a href="#simVision.swapWorkImgWithBuffer1">simVision.swapWorkImgWithBuffer1</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.workImgToBuffer1(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.workImgToBuffer1(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.workImgToBuffer2" id="simVision.workImgToBuffer2"></a>simVision.workImgToBuffer2</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the <em>work image</em> to buffer <em>buffer2</em>. See also <a href="#simVision.workImgToBuffer1">simVision.workImgToBuffer1</a>, <a href="#simVision.buffer2ToWorkImg">simVision.buffer2ToWorkImg</a> and <a href="#simVision.swapBuffers">simVision.swapBuffers</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.workImgToBuffer2(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.workImgToBuffer2(int handle)</td> 
</tr>

</table> 
<br>





<p class=subsectionBar><a name="simVision.workImgToSensorDepthMap" id="simVision.workImgToSensorDepthMap"></a>simVision.workImgToSensorDepthMap</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the <em>work image</em> (buffer used for image processing) to a vision sensor's depth buffer (each depth buffer pixel will be averaged from the image RGB-triplet). See also <a href="#simVision.workImgToSensorImg">simVision.workImgToSensorImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.workImgToSensorDepthMap(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.workImgToSensorDepthMap(int handle)</td> 
</tr>

</table> 
<br>




<p class=subsectionBar><a name="simVision.workImgToSensorImg" id="simVision.workImgToSensorImg"></a>simVision.workImgToSensorImg</p>
<table class=apiTable>
<tr class=apiTableTr> 
<td class=apiTableLeftDescr>
Description 
</td> 
<td class=apiTableRightDescr>
Copies the <em>work image</em> (buffer used for image processing) to a vision sensor's RGB buffer. See also <a href="#simVision.sensorImgToWorkImg">simVision.sensorImgToWorkImg</a>.</td>
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLSyn>
Lua synopsis
</td> 
<td class=apiTableRightLSyn>simVision.workImgToSensorImg(int handle)</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLParam>Lua parameters</td> 
<td class=apiTableRightLParam>
<div><strong>handle</strong>: handle of the vision sensor, or sim.handle_self if the object attached to this script is the vision sensor.</div>
</td> 
</tr> 
<tr class=apiTableTr> 
<td class=apiTableLeftLRet>
Lua return values
</td> 
<td class=apiTableRightLRet>
<div></div></td> 
</tr> 

<tr class="apiTableTr">
<td class=apiTableLeftPSyn>
Python synopsis
</td> 
<td class=apiTableRightPSyn>simVision.workImgToSensorImg(int handle)</td> 
</tr>

</table> 
<br>






</td></tr>
</table></div>
<script type="text/javascript">
//
view = getParameterByName('view')
document.getElementById('alphabetical').style.display = view == 'alphabetical' ? 'table-cell' : 'none'
document.getElementById('category').style.display = view == 'category' ? 'table-cell' : 'none'
document.getElementById('commands').style.display = view == null ? 'table-cell' : 'none'
document.getElementById('enums').style.display = view == null ? 'table-cell' : 'none'
document.getElementById('structs').style.display = view == null ? 'table-cell' : 'none'
document.getElementById('scriptFunctions').style.display = view == null ? 'table-cell' : 'none'
//
                </script>
</body>
</html>
